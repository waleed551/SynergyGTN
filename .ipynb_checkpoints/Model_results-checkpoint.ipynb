{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [10:39:10] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "[10:39:10] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric import data as DATA\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json,pickle\n",
    "from collections import OrderedDict\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "import networkx as nx\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_gz)\n",
    "\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "except ImportError:\n",
    "    Chem = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_features(mol):\n",
    "    symbols = ['K', 'Y', 'V', 'Sm', 'Dy', 'In', 'Lu', 'Hg', 'Co', 'Mg',    #list of all elements in the dataset\n",
    "        'Cu', 'Rh', 'Hf', 'O', 'As', 'Ge', 'Au', 'Mo', 'Br', 'Ce', \n",
    "        'Zr', 'Ag', 'Ba', 'N', 'Cr', 'Sr', 'Fe', 'Gd', 'I', 'Al', \n",
    "        'B', 'Se', 'Pr', 'Te', 'Cd', 'Pd', 'Si', 'Zn', 'Pb', 'Sn', \n",
    "        'Cl', 'Mn', 'Cs', 'Na', 'S', 'Ti', 'Ni', 'Ru', 'Ca', 'Nd', \n",
    "        'W', 'H', 'Li', 'Sb', 'Bi', 'La', 'Pt', 'Nb', 'P', 'F', 'C',\n",
    "        'Re','Ta','Ir','Be','Tl']\n",
    "\n",
    "    hybridizations = [\n",
    "        Chem.rdchem.HybridizationType.S,\n",
    "        Chem.rdchem.HybridizationType.SP,\n",
    "        Chem.rdchem.HybridizationType.SP2,\n",
    "        Chem.rdchem.HybridizationType.SP3,\n",
    "        Chem.rdchem.HybridizationType.SP3D,\n",
    "        Chem.rdchem.HybridizationType.SP3D2,\n",
    "        'other',\n",
    "    ]\n",
    "\n",
    "    stereos = [\n",
    "        Chem.rdchem.BondStereo.STEREONONE,\n",
    "        Chem.rdchem.BondStereo.STEREOANY,\n",
    "        Chem.rdchem.BondStereo.STEREOZ,\n",
    "        Chem.rdchem.BondStereo.STEREOE,\n",
    "    ]\n",
    "    features = []\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        symbol = [0.] * len(symbols)\n",
    "        symbol[symbols.index(atom.GetSymbol())] = 1.\n",
    "        #comment degree from 6 to 8\n",
    "        degree = [0.] * 8\n",
    "        degree[atom.GetDegree()] = 1.\n",
    "        formal_charge = atom.GetFormalCharge()\n",
    "        radical_electrons = atom.GetNumRadicalElectrons()\n",
    "        hybridization = [0.] * len(hybridizations)\n",
    "        hybridization[hybridizations.index(\n",
    "            atom.GetHybridization())] = 1.\n",
    "        aromaticity = 1. if atom.GetIsAromatic() else 0.\n",
    "        hydrogens = [0.] * 5\n",
    "        hydrogens[atom.GetTotalNumHs()] = 1.\n",
    "        chirality = 1. if atom.HasProp('_ChiralityPossible') else 0.\n",
    "        chirality_type = [0.] * 2\n",
    "        if atom.HasProp('_CIPCode'):\n",
    "            chirality_type[['R', 'S'].index(atom.GetProp('_CIPCode'))] = 1.\n",
    "    \n",
    "        x = torch.tensor(symbol + degree + [formal_charge] +\n",
    "                         [radical_electrons] + hybridization +\n",
    "                         [aromaticity] + hydrogens + [chirality] +\n",
    "                         chirality_type)\n",
    "        xs.append(x)\n",
    "    \n",
    "        x = torch.stack(xs, dim=0)\n",
    "\n",
    "    edge_indices = []\n",
    "    edge_attrs = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edge_indices += [[bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]]\n",
    "        edge_indices += [[bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]]\n",
    "    \n",
    "        bond_type = bond.GetBondType()\n",
    "        single = 1. if bond_type == Chem.rdchem.BondType.SINGLE else 0.\n",
    "        double = 1. if bond_type == Chem.rdchem.BondType.DOUBLE else 0.\n",
    "        triple = 1. if bond_type == Chem.rdchem.BondType.TRIPLE else 0.\n",
    "        aromatic = 1. if bond_type == Chem.rdchem.BondType.AROMATIC else 0.\n",
    "        conjugation = 1. if bond.GetIsConjugated() else 0.\n",
    "        ring = 1. if bond.IsInRing() else 0.\n",
    "        stereo = [0.] * 4\n",
    "        stereo[stereos.index(bond.GetStereo())] = 1.\n",
    "    \n",
    "        edge_attr = torch.tensor(\n",
    "            [single, double, triple, aromatic, conjugation, ring] + stereo)\n",
    "    \n",
    "        edge_attrs += [edge_attr, edge_attr]\n",
    "    \n",
    "    if len(edge_attrs) == 0:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0, 10), dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_indices).t().contiguous()\n",
    "        edge_attr = torch.stack(edge_attrs, dim=0)\n",
    "    return x, edge_index, edge_attr\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def smile_to_graph(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol == None:\n",
    "        return None\n",
    "    \n",
    "    c_size = mol.GetNumAtoms()\n",
    "    features, edge_index, edge_attr = smiles_features(mol)\n",
    "    # features = []\n",
    "    # bonds = mol.GetBonds()\n",
    "    # for atom in mol.GetAtoms():\n",
    "    #     feature = atom_features(atom)\n",
    "    #     features.append( feature / sum(feature) )\n",
    "\n",
    "    # edges = []\n",
    "    # for bond in mol.GetBonds():\n",
    "    #     edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    # g = nx.Graph(edges).to_directed()\n",
    "    # edge_index = []\n",
    "    # for e1, e2 in g.edges:\n",
    "    #     edge_index.append([e1, e2])\n",
    "        \n",
    "    return features, edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Molecule_data(InMemoryDataset):\n",
    "    def __init__(self, root='/tmp', dataset='_drug1',xd=None, xt=None, y=None, xt_featrue=None, transform=None,\n",
    "                 pre_transform=None,smile_graph=None):\n",
    "\n",
    "        #root is required for save preprocessed data, default is '/tmp'\n",
    "        super(Molecule_data, self).__init__(root, transform, pre_transform)\n",
    "        # benchmark dataset, default = 'davis'\n",
    "        self.dataset = dataset\n",
    "        if os.path.isfile(self.processed_paths[0]):\n",
    "#             print('Pre-processed data found: {}, loading ...'.format(self.processed_paths[0]))\n",
    "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        else:\n",
    "            print('Pre-processed data {} not found, doing pre-processing...'.format(self.processed_paths[0]))\n",
    "            self.process(xd, xt, xt_featrue, y, smile_graph)\n",
    "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        pass\n",
    "        #return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [self.dataset + '.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "\n",
    "    def _download(self):\n",
    "        pass\n",
    "\n",
    "    def _process(self):\n",
    "        if not os.path.exists(self.processed_dir):\n",
    "            os.makedirs(self.processed_dir)\n",
    "            \n",
    "    def get_cell_feature(self, cellId, cell_features):\n",
    "        for row in islice(cell_features, 0, None):\n",
    "            if cellId in row[0]:\n",
    "                return row[1:]\n",
    "        return False\n",
    "\n",
    "    def process(self, xd, xt, xt_featrue,y,smile_graph):\n",
    "        assert (len(xd) == len(xt) and len(xt) == len(y)), \"The three lists must be the same length!\"\n",
    "        data_list = []\n",
    "        data_len = len(xd)\n",
    "        for i in range(data_len):\n",
    "            print('Converting SMILES to graph: {}/{}'.format(i+1, data_len))\n",
    "            smiles = xd[i]\n",
    "            target = xt[i]\n",
    "            labels = y[i]\n",
    "            # convert SMILES to molecular representation using rdkit\n",
    "            x, edge_index, edge_attr = smile_graph[smiles]\n",
    "            # make the graph ready for PyTorch Geometrics GCN algorithms:\n",
    "            GCNData = Data(x=torch.Tensor(x),\n",
    "                      edge_index=edge_index,\n",
    "                      edge_attr=edge_attr,\n",
    "                      y=torch.FloatTensor([labels]))\n",
    "        \n",
    "            cell = self.get_cell_feature(target, xt_featrue)\n",
    "\n",
    "            if cell == False : \n",
    "                print('cell', cell)\n",
    "                sys.exit()\n",
    "\n",
    "            new_cell = []\n",
    "            # print('cell_feature', cell_feature)\n",
    "            for n in cell:\n",
    "                new_cell.append(float(n))\n",
    "            GCNData.cell = torch.FloatTensor([new_cell])\n",
    "            #GCNData.__setitem__('c_size', torch.LongTensor([c_size]))\n",
    "            # append graph, label and target sequence to data list\n",
    "            data_list.append(GCNData)\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "        print('Graph construction done. Saving to file.')\n",
    "        data, slices = self.collate(data_list)\n",
    "#         print(data.shape,slices.shape)\n",
    "        # save preprocessed data:\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_features [['gene_id' 'ENSG00000116237' 'ENSG00000162413' ... 'ENSG00000157617'\n",
      "  'ENSG00000160208' 'ENSG00000141959']\n",
      " ['transcript_id' 'ENST00000343813' 'ENST00000377658' ...\n",
      "  'ENST00000329623' 'ENST00000340648' 'ENST00000349048']\n",
      " ['A2058' '51.07' '20.76' ... '1.46' '23.67' '78.86']\n",
      " ...\n",
      " ['UACC62' '19.16' '19.6' ... '0' '17.3' '60.09']\n",
      " ['VCAP' '50.7' '7.41' ... '3.75' '28.45' '72.63']\n",
      " ['ZR751' '30.69' '4.72' ... '0.77' '6.8' '36.37']]\n",
      "开始创建数据\n",
      "创建数据成功\n",
      "preparing  new_labels_0_10_.pt in pytorch format!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import islice\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json, pickle\n",
    "from collections import OrderedDict\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def creat_data(datafile, cellfile):\n",
    "    file2 = cellfile\n",
    "    cell_features = []\n",
    "    with open(file2) as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)  # 使用csv.reader读取csvfile中的文件\n",
    "        for row in csv_reader:\n",
    "            cell_features.append(row)\n",
    "    cell_features = np.array(cell_features)\n",
    "    print('cell_features', cell_features)\n",
    "\n",
    "    compound_iso_smiles = []\n",
    "    df = pd.read_csv('/home/waleed/graph/New_Expriment/data/smiles.csv')\n",
    "    compound_iso_smiles += list(df['smile'])\n",
    "    compound_iso_smiles = set(compound_iso_smiles)\n",
    "    smile_graph = {}\n",
    "    for smile in compound_iso_smiles:\n",
    "        g = smile_to_graph(smile)\n",
    "        smile_graph[smile] = g\n",
    "\n",
    "    datasets = datafile\n",
    "    # convert to PyTorch data format\n",
    "    processed_data_file_train = 'data_perparation/processed/' + datasets + '_train.pt'\n",
    "\n",
    "    if ((not os.path.isfile(processed_data_file_train))):\n",
    "        df = pd.read_csv('/home/waleed/graph/New_Expriment/data/' + datasets + '.csv')\n",
    "        drug1, drug2, cell, label = list(df['drug1']), list(df['drug2']), list(df['cell']), list(df['label'])\n",
    "        drug1, drug2, cell, label = np.asarray(drug1), np.asarray(drug2), np.asarray(cell), np.asarray(label)\n",
    "        # make data PyTorch Geometric ready\n",
    "\n",
    "        print('开始创建数据')\n",
    "        Molecule_data(root='data_perparation', dataset=datafile + '_drug1', xd=drug1, xt=cell, xt_featrue=cell_features, y=label,smile_graph=smile_graph)\n",
    "        Molecule_data(root='data_perparation', dataset=datafile + '_drug2', xd=drug2, xt=cell, xt_featrue=cell_features, y=label,smile_graph=smile_graph)\n",
    "        print('创建数据成功')\n",
    "        print('preparing ', datasets + '_.pt in pytorch format!')\n",
    "    #\n",
    "    #     print(processed_data_file_train, ' have been created')\n",
    "    #\n",
    "    # else:\n",
    "    #     print(processed_data_file_train, ' are already created')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # datafile = 'prostate'\n",
    "    cellfile = '/home/waleed/graph/New_Expriment/data/new_cell_features_954.csv'\n",
    "    da = ['new_labels_0_10']\n",
    "    for datafile in da:\n",
    "        creat_data(datafile, cellfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import GATConv,TransformerConv\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.nn import max_pool as mxp\n",
    "from torch_geometric.nn import avg_pool as agp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GAT  model\n",
    "class TransfGNN1(torch.nn.Module):\n",
    "    def __init__(self, num_features_xd=92, n_output=2, num_features_xt=954, output_dim=128, dropout=0.05, file=None):\n",
    "        super(TransfGNN1, self).__init__()\n",
    "\n",
    "        # graph drug layers\n",
    "        self.drug1_gcn1 = TransformerConv(num_features_xd, output_dim, heads=10,edge_dim=10, dropout=dropout)\n",
    "        self.drug1_gcn2 = TransformerConv(output_dim *10, output_dim,edge_dim=10, dropout=dropout)\n",
    "        #self.drug1_gcn3 = GATConv(output_dim *20, output_dim,edge_dim=10, dropout=dropout)\n",
    "        self.drug1_fc_g1 = nn.Linear(output_dim, output_dim)\n",
    "        # self.drug1_fc_g2 = nn.Linear(2048, output_dim)\n",
    "        self.filename = file\n",
    "\n",
    "\n",
    "        # DL cell featrues\n",
    "        self.reduction = nn.Sequential(\n",
    "            nn.Linear(num_features_xt, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, output_dim * 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        # combined layers\n",
    "        self.fc1 = nn.Linear(output_dim * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        #self.fc3 = nn.Linear(256, 128)\n",
    "        self.out = nn.Linear(128, n_output)\n",
    "\n",
    "        # activation and regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def get_col_index(self, x):\n",
    "        row_size = len(x[:, 0])\n",
    "        row = np.zeros(row_size)\n",
    "        col_size = len(x[0, :])\n",
    "        for i in range(col_size):\n",
    "            row[np.argmax(x[:, i])] += 1\n",
    "        return row\n",
    "\n",
    "    def save_num(self, d, path):\n",
    "        d = d.cpu().numpy()\n",
    "        ind = self.get_col_index(d)\n",
    "        ind = pd.DataFrame(ind)\n",
    "        ind.to_csv('data/case_study/' + path + '_index.csv', header=0, index=0)\n",
    "\n",
    "    def forward(self, data1, data2):\n",
    "        x1, edge_index1,edge_attr1, batch1, cell = data1.x.float(), data1.edge_index,data1.edge_attr, data1.batch, data1.cell\n",
    "        \n",
    "        x2, edge_index2,edge_attr2, batch2 = data2.x.float(), data2.edge_index,data2.edge_attr, data2.batch\n",
    "        # deal drug1\n",
    "        x1 = self.drug1_gcn1(x1, edge_index=edge_index1,edge_attr=edge_attr1)\n",
    "        x1 = F.relu(x1)\n",
    "        #x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "        x1 = self.drug1_gcn2(x1, edge_index=edge_index1,edge_attr=edge_attr1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        #x1 = self.drug1_gcn3(x1, edge_index=edge_index1,edge_attr=edge_attr1)\n",
    "        #x1 = F.relu(x1)\n",
    "        #x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "    \n",
    "        x1 = gmp(x1,batch1)         # global max pooling\n",
    "\n",
    "\n",
    "        x1 = self.drug1_fc_g1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        # x1 = self.drug1_fc_g2(x1)\n",
    "        # x1 = self.relu(x1)\n",
    "\n",
    "        # deal drug2\n",
    "    \n",
    "        x2 = self.drug1_gcn1(x2, edge_index2,edge_attr=edge_attr2)\n",
    "        x2 = F.relu(x2)\n",
    "        #x2 = F.dropout(x2, p=0.1, training=self.training)\n",
    "        x2 = self.drug1_gcn2(x2, edge_index2,edge_attr=edge_attr2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        #x2 = self.drug1_gcn3(x2, edge_index=edge_index2,edge_attr=edge_attr2)\n",
    "        #x2 = F.relu(x2)\n",
    "        #x2 = F.dropout(x2, p=0.1, training=self.training)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        x2 = gmp(x2,batch2)  # global max pooling\n",
    "\n",
    "\n",
    "        x2 = self.drug1_fc_g1(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        # x2 = self.drug1_fc_g2(x2)\n",
    "        # x2 = self.relu(x2)\n",
    "\n",
    "        # deal cell\n",
    "        cell = F.normalize(cell, 2, 1)\n",
    "        cell_vector = self.reduction(cell)\n",
    "\n",
    "\n",
    "\n",
    "        # concat\n",
    "        xc = torch.cat((x1, x2, cell_vector), 1)\n",
    "        xc = F.normalize(xc, 2, 1)\n",
    "        # add some dense layers\n",
    "        xc = self.fc1(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        xc = self.fc2(xc)\n",
    "        xc = self.relu(xc)\n",
    "        #xc = self.dropout(xc)\n",
    "        #xc = self.fc3(xc)\n",
    "        #xc = self.relu(xc)\n",
    "        #xc = self.dropout(xc)\n",
    "        out = self.out(xc)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix,recall_score,matthews_corrcoef,roc_curve,roc_auc_score,auc,precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from random import shuffle\n",
    "\n",
    "def analyze(temp, OutputDir):\n",
    "    file = open(OutputDir + '/performance.txt', 'w')\n",
    "    testing_result = temp\n",
    "    index = 0\n",
    "\n",
    "\n",
    "    for x in [testing_result]:\n",
    "\n",
    "\n",
    "        title = ''\n",
    "\n",
    "        if index == 0:\n",
    "            title = 'testing_'\n",
    "\n",
    "        index += 1\n",
    "\n",
    "        file.write(title +  'results\\n')\n",
    "\n",
    "\n",
    "        for j in ['sn', 'sp', 'acc', 'MCC','AUC', 'precision', 'F1']: #,'pre_recall_curve'\n",
    "\n",
    "            total = []\n",
    "\n",
    "            for val in x:\n",
    "                total.append(val[j])\n",
    "            file.write(j + ' : mean : ' + str(np.mean(total)) + ' std : ' + str(np.std(total))  + '\\n')\n",
    "\n",
    "        file.write('\\n\\n______________________________\\n')\n",
    "\n",
    "\n",
    "    index = 0\n",
    "\n",
    "\n",
    "    for x in [testing_result]:\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for val in x:\n",
    "            tpr = val['tpr']\n",
    "            fpr = val['fpr']\n",
    "            tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "            tprs[-1][0] = 0.0\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "            plt.plot(fpr, tpr, lw=1, alpha=0.3,label='ROC fold %d (AUC = %0.3f)' % (i+1, roc_auc))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Random', alpha=.8)\n",
    "\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "                 label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        title = ''\n",
    "\n",
    "        if index == 0:\n",
    "            title = 'testing_'\n",
    "        \n",
    "\n",
    "        plt.savefig( OutputDir+ '/' +title +'ROC.png')\n",
    "        plt.close('all')\n",
    "\n",
    "       #************************** Precision Recall Curve*********************************\n",
    "        i = 0\n",
    "        prs = []\n",
    "        pre_aucs = []\n",
    "        mean_recal= np.linspace(0, 1, 100)\n",
    "        for val in x:\n",
    "            pre = val['prec']\n",
    "            rec = val['reca']\n",
    "            prs.append(interp(mean_recal, rec, pre))\n",
    "            prs[-1][0] = 0.0\n",
    "            p_r_auc = auc(rec, pre)\n",
    "            pre_aucs.append(p_r_auc)\n",
    "            plt.plot(rec, pre, lw=1, alpha=0.3,label='PRC fold %d (AUC = %0.3f)' % (i+1, p_r_auc))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Random', alpha=.8)\n",
    "\n",
    "        mean_pre = np.mean(prs, axis=0)\n",
    "        mean_pre[-1] = 1.0\n",
    "        mean_auc = auc(mean_recal, mean_pre)\n",
    "        std_auc = np.std(pre_aucs)\n",
    "        plt.plot(mean_recal, mean_pre, color='b',\n",
    "                 label=r'Mean PRC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "\n",
    "        std_pre = np.std(prs, axis=0)\n",
    "        pre_upper = np.minimum(mean_pre + std_pre, 1)\n",
    "        pre_lower = np.maximum(mean_pre - std_pre, 0)\n",
    "        plt.fill_between(mean_recal, pre_lower, pre_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision Recall curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        title = ''\n",
    "\n",
    "        if index == 0:\n",
    "            title = 'testing_'\n",
    "    \n",
    "\n",
    "        plt.savefig( OutputDir + '/'+ title +'Pre_R_C.png')\n",
    "        plt.close('all');\n",
    "\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    file.close()\n",
    "    #plot_Roc(val_ROC_result_table,0 )\n",
    "    #plot_Roc(test_ROC_result_table,1 )\n",
    "    #plot_Roc(val_PRC_result_table,2 )\n",
    "    #plot_Roc(test_PRC_result_table,3 )\n",
    "def calculateScore(y,pred_y):\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "     \n",
    "    ROCArea = roc_auc_score(y, pred_y)\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred_y)\n",
    "    lossValue = None;\n",
    "    \n",
    "    pre, rec, threshlds = precision_recall_curve(y, pred_y)\n",
    "    pre = np.fliplr([pre])[0]  #so the array is increasing (you won't get negative AUC)\n",
    "    rec = np.fliplr([rec])[0]  \n",
    "    AUC_prec_rec = np.trapz(rec,pre)\n",
    "    AUC_prec_rec = abs(AUC_prec_rec)\n",
    "    \n",
    "    pred_y[pred_y > 0.5] = 1\n",
    "    pred_y[~(pred_y > 0.5)] = 0\n",
    "    \n",
    "    label = np.column_stack((y, pred_y))\n",
    "    for i in range(len(label)):\n",
    "        if label[i][0] == 0:\n",
    "            if label[i][1] == 0:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "        else:\n",
    "            if label[i][1] == 0:\n",
    "                fn = fn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    #MCC = matthews_corrcoef(y, pred_y)\n",
    "    MCC = ((tp * tn) - (fp * fn)) / math.sqrt((tp + fn) * (tp + fp) * (tn + fn) * (tn + fp))\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    F1Score =  precision * recall * 2 / (precision + recall)\n",
    "\n",
    "\n",
    "    return {'sn' : sensitivity, 'sp' : specificity, 'acc' : accuracy, 'MCC' : MCC, 'AUC' : ROCArea,'precision' : precision, 'F1' : F1Score, 'fpr' : fpr, 'tpr' : tpr, 'thresholds' : thresholds,'pre_recall_curve':AUC_prec_rec,'prec':pre,'reca':rec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code uses GPU...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransfGNN1:\n\tsize mismatch for drug1_gcn1.lin_key.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_key.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn1.lin_query.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_query.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn1.lin_value.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_value.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn1.lin_edge.weight: copying a param with shape torch.Size([2560, 10]) from checkpoint, the shape in current model is torch.Size([1280, 10]).\n\tsize mismatch for drug1_gcn1.lin_skip.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_skip.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn2.lin_key.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for drug1_gcn2.lin_query.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for drug1_gcn2.lin_value.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for drug1_gcn2.lin_skip.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8643/221984833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrug1_gcn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'best_models/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/TransfGNN_model'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mindependent_drug1_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMolecule_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data_perparation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatafile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_drug1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mdrug1_loader_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindependent_drug1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_BATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1483\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TransfGNN1:\n\tsize mismatch for drug1_gcn1.lin_key.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_key.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn1.lin_query.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_query.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn1.lin_value.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_value.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn1.lin_edge.weight: copying a param with shape torch.Size([2560, 10]) from checkpoint, the shape in current model is torch.Size([1280, 10]).\n\tsize mismatch for drug1_gcn1.lin_skip.weight: copying a param with shape torch.Size([2560, 92]) from checkpoint, the shape in current model is torch.Size([1280, 92]).\n\tsize mismatch for drug1_gcn1.lin_skip.bias: copying a param with shape torch.Size([2560]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for drug1_gcn2.lin_key.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for drug1_gcn2.lin_query.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for drug1_gcn2.lin_value.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for drug1_gcn2.lin_skip.weight: copying a param with shape torch.Size([128, 2560]) from checkpoint, the shape in current model is torch.Size([128, 1280])."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "from random import shuffle\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "def predicting(model, device, drug1_loader_test, drug2_loader_test):\n",
    "    #model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    total_prelabels = torch.Tensor()\n",
    "    print('Make prediction for {} samples...'.format(len(drug1_loader_test.dataset)))\n",
    "    with torch.no_grad():\n",
    "        for data in zip(drug1_loader_test, drug2_loader_test):\n",
    "            data1 = data[0]\n",
    "            data2 = data[1]\n",
    "            data1 = data1.to(device)\n",
    "            data2 = data2.to(device)\n",
    "            output = model(data1, data2) #data.x.float(), data.edge_index,data.batch\n",
    "            ys = F.softmax(output, 1).to('cpu').data.numpy()\n",
    "            predicted_labels = list(map(lambda x: np.argmax(x), ys))\n",
    "            predicted_scores = list(map(lambda x: x[1], ys))\n",
    "            total_preds = torch.cat((total_preds, torch.Tensor(predicted_scores)), 0)\n",
    "            total_prelabels = torch.cat((total_prelabels, torch.Tensor(predicted_labels)), 0)\n",
    "            total_labels = torch.cat((total_labels, data1.y.view(-1, 1).cpu()), 0)\n",
    "    return total_labels.numpy().flatten(), total_preds.numpy().flatten(), total_prelabels.numpy().flatten()\n",
    "\n",
    "\n",
    "# CPU or GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('The code uses GPU...')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('The code uses CPU!!!')\n",
    "\n",
    "results = []\n",
    "TEST_BATCH_SIZE = 128\n",
    "#drug1_data = TestbedDataset(root='data_perparation', dataset=datafile + '_drug1')\n",
    "#drug2_data = TestbedDataset(root='data_perparation', dataset=datafile + '_drug2')\n",
    "testing_result = []\n",
    "tissues = ['breast','colon','lung','melanoma','ovarian','prostate']\n",
    "for tissue in tissues:\n",
    "    \n",
    "    datafile = tissue\n",
    "    OutputDir='/home/waleed/graph/New_Expriment/Model_Results/Results/'+datafile+'/'\n",
    "    for i in range(5):\n",
    "        model = TransfGNN1().to(device)\n",
    "        model.drug1_gcn1.head=20\n",
    "        path = 'best_models/'+datafile+'/TransfGNN_model' + str(i) + '.model'\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        independent_drug1_data = Molecule_data(root='data_perparation', dataset=datafile + '_drug1')\n",
    "        drug1_loader_test = DataLoader(independent_drug1_data, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "        independent_drug2_data = Molecule_data(root='data_perparation', dataset=datafile + '_drug2')\n",
    "        drug2_loader_test = DataLoader(independent_drug2_data, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "        T, S, Y = predicting(model, device, drug1_loader_test, drug2_loader_test)\n",
    "        testing_result.append(calculateScore(T, S))\n",
    "        AUC = roc_auc_score(T, S)\n",
    "        precision, recall, threshold = metrics.precision_recall_curve(T, S)\n",
    "        PR_AUC = metrics.auc(recall, precision)\n",
    "        BACC = balanced_accuracy_score(T, Y)\n",
    "        tn, fp, fn, tp = confusion_matrix(T, Y).ravel()\n",
    "        TPR = tp / (tp + fn)\n",
    "        PREC = precision_score(T, Y)\n",
    "        ACC = accuracy_score(T, Y)\n",
    "        print(AUC,PR_AUC,BACC)\n",
    "        KAPPA = cohen_kappa_score(T, Y)\n",
    "        recall = recall_score(T, Y)\n",
    "\n",
    "        # save data\n",
    "        AUCs = [AUC, PR_AUC, ACC, BACC, PREC, TPR, KAPPA, recall]\n",
    "        results.append(AUC)\n",
    "    res_arr = np.asarray(results)\n",
    "    print(np.average(res_arr))\n",
    "    temp_dict = (testing_result)\n",
    "    analyze(temp_dict, OutputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Independent test set\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "from random import shuffle\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#torch.manual_seed(23)\n",
    "#np.random.seed(23)\n",
    "\n",
    "def predicting(model, device, drug1_loader_test, drug2_loader_test):\n",
    "    #model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    total_prelabels = torch.Tensor()\n",
    "    print('Make prediction for {} samples...'.format(len(drug1_loader_test.dataset)))\n",
    "    with torch.no_grad():\n",
    "        for data in zip(drug1_loader_test, drug2_loader_test):\n",
    "            data1 = data[0]\n",
    "            data2 = data[1]\n",
    "            data1 = data1.to(device)\n",
    "            data2 = data2.to(device)\n",
    "            output = model(data1, data2) #data.x.float(), data.edge_index,data.batch\n",
    "            ys = F.softmax(output, 1).to('cpu').data.numpy()\n",
    "            predicted_labels = list(map(lambda x: np.argmax(x), ys))\n",
    "            predicted_scores = list(map(lambda x: x[1], ys))\n",
    "            total_preds = torch.cat((total_preds, torch.Tensor(predicted_scores)), 0)\n",
    "            total_prelabels = torch.cat((total_prelabels, torch.Tensor(predicted_labels)), 0)\n",
    "            total_labels = torch.cat((total_labels, data1.y.view(-1, 1).cpu()), 0)\n",
    "    return total_labels.numpy().flatten(), total_preds.numpy().flatten(), total_prelabels.numpy().flatten()\n",
    "\n",
    "\n",
    "# CPU or GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('The code uses GPU...')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('The code uses CPU!!!')\n",
    "\n",
    "results = []\n",
    "TEST_BATCH_SIZE = 100\n",
    "#drug1_data = TestbedDataset(root='data_perparation', dataset=datafile + '_drug1')\n",
    "#drug2_data = TestbedDataset(root='data_perparation', dataset=datafile + '_drug2')\n",
    "\n",
    "datafile ='independent_input'\n",
    "for i in range(5):\n",
    "    model = TransfGNN().to(device)\n",
    "    path = 'best_models/TransfGNN_model' + str(i) + '.model'\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    independent_drug1_data = TestbedDataset(root='/home/waleed/graph/New_Expriment/data_perparation', dataset=datafile + '_drug1')\n",
    "    drug1_loader_test = DataLoader(independent_drug1_data, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "    independent_drug2_data = TestbedDataset(root='/home/waleed/graph/New_Expriment/data_perparation', dataset=datafile + '_drug2')\n",
    "    drug2_loader_test = DataLoader(independent_drug2_data, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "    T, S, Y = predicting(model, device, drug1_loader_test, drug2_loader_test)\n",
    "    AUC = roc_auc_score(T, S)\n",
    "    precision, recall, threshold = metrics.precision_recall_curve(T, S)\n",
    "    PR_AUC = metrics.auc(recall, precision)\n",
    "    BACC = balanced_accuracy_score(T, Y)\n",
    "    tn, fp, fn, tp = confusion_matrix(T, Y).ravel()\n",
    "    TPR = tp / (tp + fn)\n",
    "    PREC = precision_score(T, Y)\n",
    "    ACC = accuracy_score(T, Y)\n",
    "    print(AUC,ACC,BACC)\n",
    "    KAPPA = cohen_kappa_score(T, Y)\n",
    "    recall = recall_score(T, Y)\n",
    "\n",
    "    # save data\n",
    "    AUCs = [AUC, PR_AUC, ACC, BACC, PREC, TPR, KAPPA, recall]\n",
    "    results.append(KAPPA)\n",
    "res_arr = np.asarray(results)\n",
    "print(np.average(res_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
